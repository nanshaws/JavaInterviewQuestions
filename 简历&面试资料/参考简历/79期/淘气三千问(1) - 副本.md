## 一、自我介绍

面试官您好，我是来自湖南湘潭的袁书平，至今参与java工作已经有4年多的时间了，参与过单体架构项目与一些分布式架构微服务开发，熟悉目前市场上常用的框架,中间件 如spring、springBoot、springMvc、mybatis,mysql，redis，ElasticSearch 等；在闲暇时间会看看B站或者官网学习新技术的习惯，逛一些技术贴，提高自己的知识面，对技术进行迭代或提升认识。



广东力通网络科技有限公司

广州市天河区建中路58号东诚大厦403-406



## 二、项目简介

穗佳物流运输系统是一款TMS运配系统，它从三个方面解决了物流的运送问题，货物取派，车辆安排，路线规划；客户通过微信下单，快递员取件，系统进行调度安排车辆，规划最佳路线送到取件人附近站点最后安排配送，整个过程客户可以通过手机查看物流信息；

整个项目分为四个端：

用户端：基于微信小程序开发，外部客户使用，可以寄件，查询物流信息等.

快递员端：基于安卓开发的手机APP，公司内部快递员进行使用，可以接收取派快递任务等.

司机端: 基于安卓开发的手机APP，公司内部的司机使用，可以接收运输任务，上报位置信息等.

后台系统管理端: 基于vue开发，PC端使用，公司内部管理员用户使用，可以进行基础数据维护，订单管理，运单管理等.



## 三、使用技术

主架构：springBoot + mybatis + mybatis-plus + mongoDB + SpringCloud Alibaba
        中间价：缓存redis + 消息rabbitmq + ElastcSerach + Neo4j + XXL-Job
        第三方：微信，支付宝支付功能+权限管家+高德地图

## 四、项目介绍

我负责的是运费模块，路线规划模块及任务调度+运输任务模块

### 1.运费微服务

所用的表只有一个运费模板表，其中有模板的id，模板类型，运送方式，关联城市，首重价格，续重价格，轻抛系数等。

运费计算我们有设置运费模板，其中分为同城，省内，经济区互寄，省外，根据不同的模板计算不同的价格，而运费模板的判断我们有使用责任链设计模式去进行匹配，每一个模板我们都写了一个类，根据Order注解进行优先级排序，再把这些对象组装成链，在链中一个个去调用，当传来的参数与当前模板匹配我们就进行返回，如果不符合就去下一节点做匹配；当拿到匹配的模板后，我们就会去根据货物的重量进行运费的计算，首先判断货物的重量与体积，看哪个比较大， 由于重量体积不是一个计量单位，我们有使用体积除以轻抛系数去得出它对应的重量，进行判断，得到重量后，根据  续重-1 * 续重价格 +首重价格  最终得出货物的运费。

当时在对运费计算模块进行测试时，会发现效率越来越低，经过排查后发现，在查询运费模板的过程中会对数据库进行多次的访问，导致性能下降， 后面就去使用了redis对模板进行了缓存，因为模板是一个不经常改变的数据。

### 2.路线规划

路线规划我们使用的是Neo4j图数据库，它使用节点，属性，关系，标签来储存数据，

当时对其设置的基本参数有：机构id，名称，类型，地址，经纬度，父节点id，是否可用等

路线规划，我们选用的是Neo4j图数据库进行管理，因为它实现了专业数据库级别的图数据模型存储，提供完整的数据库特性，包括ACID事务支持，备份，故障转移等，查询效率高，有较高的扩展性，通过图与线就能把数据展示出来。

我们对货物到达及中转的地方设置了机构名分为一级转运中心，二级分拣中心，营业部，机构与机构之间的路线又分为一级转运到一级转运的路线叫做干线，一级转运到二级分拣的叫做支线，二级分拣到营业部的叫接驳路线，都是后台系统对路线进行CRUD操作，通过MQ进行与Neo4j的数据同步。

当用户下单后，订单微服务会携带起始营业点与终点营业点id到路线规划微服务进行路线的查询，当知道两点的营业部地点后，就能够借助Neo4j中的查询来完成路线的规划，最后返回完整路线。

### 3.调度任务 	

而调度中心，主要是使用运单表，运单与运输任务关联表，员工排班信息表等。

而运单表通过订单id跟订单表进行关联，获得订单中的货物总重量体积，同时还可以通过订单表中的起始终点地址获得起始网点id跟终点网点id，而运单表又会存当前机构id跟下一个机构id还有完整运输路线



调度中心对货物整个流程中所需的快递员，车辆司机，运输节点进行统筹。

当订单微服务接到客户下单，会通过MQ发送消息给到调度中心，调度中心对营业点的快递员进行一个挑选，优先挑选有排班的并在有排班的快递员中选择任务数量最少的，最后封装快递员信息发送给运单微服务，让其生成取件任(派件任务流程相同)。

调度中心通过mq去监听新增的运单信息，获取当前机构id与下一个机构id设置set结构redis的key，并对消息进行幂等性处理（就是判断这个key中是否存在当前运单id）判断设置的key中是否存在当前信息的运单id，如果不存在就存入redis中， 同时将消息数据进行封装通过list结构存入redis中，这都是为后面合并运单与装车做准备。

调度中心会通过XXL-Job分片广播对2小时可用车辆进行查询，并通过起始机构与结束机构进行判断是否符合要求，如果符合要求根据车辆的开始机构id与结束机构id去添加list结构的前缀用来确定需要处理的运单集合，车辆确认好后，就需要对运力进行计算与运单进行合并，但之前需要设置分布式锁，防止其他线程同时进行操作。

使用递归的方式，从redis最右边删除并取出list结构的key获取其value值，根据其货物总重量与货物总体积算出载重与体积，再算出车辆的总容积和载重(需要注意车辆要留有缝隙，所以设置了0.95的乘积)，最后进行判断货物的载重与体积有没有超过车辆剩余载重与容积，如果有一个超出，就把该运单重新添加回redis，为了先入先出要添加到最右边，如果没有超出，就将运单添加入集合，并递归处理运单( 在这个递归方法根据判断运单是否为空与容积是否超出，来跳出递归),     当车辆装满，就去创建运输任务，封装参数（简单说几个：运单合并集合，司机id，车辆id，开始机构id，结束机构id）通过MQ发送消息生成运输任务，  发送完消息后，还有一个需要做的就是删除redis中set结构的key，表示运单已经进行调度，  最后还会要发送消息通知车辆已完成调度， 这两条消息都是发给运单微服务去生成运输任务，并创建运输任务与运单的关系。

### 4.运输任务

运输任务主要是控制运输任务表，其中通过运单与运输任务表去关联运单表中的数据，而且还通过车辆计划id跟车次id关联了车辆计划表等，  运输任务表中通过运单表获得起始机构id跟目的机构id，通过id获得地址名去第三方高德地图获得交付提货经纬度跟距离，而通过车辆计划表可以获得车次id，车辆id等

**1.创建运输任务**

运单微服务接收生成运输任务信息，对信息进行解析，获取司机id进行判断是否为空，如果为空分配状态成待人工分配， 然后开始创建运输任务，根据车辆计划id查询预计发车时间和预计到达时间，创建运输任务对象，把数据进行填充，并判断是满载还是空载，然后进行保存。

接着会需要创建运输任务与运单列表之间的关系，把运单列表id与运输任务id保存到对应的关联表中，并把运单列表中的运单批量修改成调度状态，最后调用司机微服务方法生成司机作业单。

**2.车辆出库**

运输任务中还包含车辆的入库与出库操作。

当生成了司机作业单，司机根据手机APP任务去指定地点进行装货，当装完货物后点击提货按键，就会对车辆做出库处理

根据提货对象获取司机作业单对象，进行判断对象是否为空，状态是否为待执行，司机有无其他任务，

接着会需要上锁处理，表示同一时间只能一个司机进行操作，其中会进行运输任务的查询，判断任务是否为运行或已取消状态。

根据运输任务id查询运输任务列表，并将状态都修改成运输中，接着提货对象转成运输开始对象并调用运单微服务设置新的运输任务表修改状态，上传图片，发车时间   完成及释放锁。

修改所有与此次运输任务id想关联的司机作业表及实际出发时间，调用基础微服务，并把车辆状态也要修改成运输中，整个方法需要注意事务问题，最好添加@GlobalTransactional注解

**3.车辆入库**

司机根据司机作业单把货物送到指定地点进行入库操作

通过司机作业单id获取运输任务对象，并进行判断是否为空，状态是否为运行中，

接着通过运输对象获取运输任务id，并设置分布式锁，防止司机多次点击完成任务操作，

然后通过远程调用运单微服务通过运输任务id查询运输任务信息，并判断任务是否已结束或已交付，如果是的就不流转了， 如果不是就修改运单流转节点，调用运单微服务方法，通过运输任务id查询运单id列表，对运单列表做循环操作，把下一个机构设置为当前机构，获取完整运输路线，对其进行解析，通过getJSONArray获取里面的集合，并对集合进行反向循环操作(这里是因为会有拒收情况所以要反方向)，进行判断是否为当前节点id不是就下一个，如果是就继续进行判断，如果当前索引等于数组长度减一，表示到达最后一个节点，则修改状态为到达最终网点，如果不是则改为待调度，最后要把下一个节点设置到对象中，   最后判断运单状态是否为到达最终网点，如果是就调用方法发送消息安排派件任务，跟安排取件任务差不多，  而不是最终网点则调用方法，发送消息到运单调度的交换机中进行下一次调度安排，最后批量更新运单。

最后把运输任务id赋值给运输任务结束实体，根据实体调用运单微服务进行结束运输任务，最后释放锁。

当然还要修改所有与运输任务id相关联的司机作业单状态跟实际达到时间，表明本次运输已结束。



## **MongoDB**

      MongoDB非关系数据库

它支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数
据类型。Mongo最大的特点是它支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几
乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。

**MongoDB和Redis的区别是什么**

 1、内存管理机制 Redis 数据全部存在内存，定期写入磁盘，当内存不够时，可以选择指定的 LRU 算法删除数据。 MongoDB 数据存在内存，由 linux系统 mmap 实现，当内存不够时，只将热点数据放入内存，其他数据存在磁盘。 

2、支持的数据结构 Redis 支持的数据结构丰富，包括hash、set、list等。 MongoDB 数据结构比较单一，但是支持丰富的数据表达，索引，最类似[关系型数据库](https://cloud.tencent.com/product/cdb-overview?from=10680)，支持的查询语言非常丰富。 

3、数据量和性能： 当物理内存够用的时候，**redis>mongodb>mysql** 当物理内存不够用的时候，redis和mongodb都会使用虚拟内存。 实际上如果redis要开始虚拟内存，那很明显要么加内存条，要么你换个数据库了。 但是，mongodb不一样，只要，业务上能保证，冷热数据的读写比，使得热数据在物理内存中，mmap的交换较少。 mongodb还是能够保证性能。 

4、性能 mongodb依赖内存，TPS较高；Redis依赖内存，TPS非常高。性能上Redis优于MongoDB。 

5、可靠性 mongodb从1.8版本后，采用binlog方式（MySQL同样采用该方式）支持持久化，增加可靠性； Redis依赖快照进行持久化；AOF增强可靠性；增强可靠性的同时，影响访问性能。 可靠性上MongoDB优于Redis。 6、数据分析 mongodb内置数据分析功能（mapreduce）；而Redis不支持。

 7、事务支持情况 Redis 事务支持比较弱，只能保证事务中的每个操作连续执行；mongodb不支持事务。

 8、集群 MongoDB 集群技术比较成熟，Redis从3.0开始支持集群。

**mysql和mongdb**

| 数据库       | MongoDB                                              | MySQL                        |
| :----------- | :--------------------------------------------------- | :--------------------------- |
| 数据库模型   | 非关系型                                             | 关系型                       |
| 存储方式     | 以类JSON的文档的格式存储                             | 不同引擎有不同的存储方式     |
| 查询语句     | MongoDB查询方式（类似JavaScript的函数）              | SQL语句                      |
| 数据处理方式 | 基于内存，将热数据存放在物理内存中，从而达到高速读写 | 不同引擎有自己的特点         |
| 成熟度       | 新兴数据库，成熟度较低                               | 成熟度高                     |
| 广泛度       | NoSQL数据库中，比较完善且开源，使用人数在不断增长    | 开源数据库，市场份额不断增长 |
| 事务性       | 仅支持单文档事务操作，弱一致性                       | 支持事务操作                 |
| 占用空间     | 占用空间大                                           | 占用空间小                   |
| join操作     | MongoDB没有join                                      | MySQL支持join                |


## Linux命令

**日志：**

tail  -n  10   test.log   查询日志尾部最后10行的日志;                                                                                                    tail  -n +10   test.log   查询10行之后的所有日志;

head -n  10  test.log   查询日志文件中的头10行日志;                                                                                                head -n -10  test.log   查询日志文件除了最后10行的其他所有日志;

ls [目录名] ，查看当前目录下的内容 ；pwd ，查看当前所在目录 ；cd [目录名] ，切换目录 ；rm -rf(删除)慎用                                  touch [文件名] ，如果文件不存在,创建文件 ； mkdir [目录名] ，创建目录 ；   rm [文件名] ，删除指定文件；



## 集合线程安全问题

HashTable、Properties是线程安全的；

ArrayList、LinkedList、HashSet、TreeSet、HashMap、TreeMap等都是线程不安全的。

## 数据库优化方案

1. 设计表的时候严格按照数据库设计规范来设计数据库
2. 使用缓存，把经常访问并且不需要经常变化的数据放在缓存中，能够节约磁盘IO
3. 优化硬件，采用ssd，使用磁盘队列技术（RAID0， RAID1，RAID5）
4. 采用mysql自带的表分区技术，把数据分析分成不同文件，能够磁盘的读写效率
5. 垂直分表，把一些不经常读的数据放在一张表当中，节约磁盘IO
6. 主从分离读写，采用主从复制把数据库的读操作和写操作分离开来
7. 分库分表分机器，数据量特别大的时候，主要的原理是数据路由
8. 选择合适的表引擎，参数上的优化
9. 进行架构级别的缓存，静态化和分布式
10. 不采用全文检索
11. 采用更快的存储方恨少，例如nosql存储经常访问的数据




## 难点

....



##### 三范式:

数据库表中的每一列都不可再分，也就是**原子性**,两张表要通过外键关联，不保存冗余字段,表中的非主键字段和主键字段直接相关，不允许间接相关

**表结构设计问题**

需要修改

对应的表结构设计有些属于三范式有些为了效率用到了违反三范式的设定,比如app端信息表结构设计就拆分成了三张表对应的信息配置表和信息详情表,但是在自媒体端的信息表我并没有拆分因为涉及到了阿里云第三方接口信息自动审核,为了提升效率我仅仅只把信息对应的类型拆分出去单独成表详情和一些配置信息全都在一张表中了.

### 问题一：表设计

**你有没有参与过表设计？如何进行表设计？**

这个项目，我是从项目启动时就进入的，参与了表设计和接口设计。设计数据库表，我的经验就是先从产品原型中提炼出表名称，比如产品原型中，有一些基础数据的维护，那么这些大概率都是一些基本表。这类的表设计相对比较简单，就是从产品原型中提取输入和输出项，此外，我们还会加上逻辑删除字段、状态字段、创建日期和更新日期这样的字段。  另外还有一些经验，虽然理论上我们要遵循三大范式，但是实际上是要有变通的，比如空间换时间。

### 问题二：你们项目开发流程是什么：

我们项目采用前后端分离的模式开发。

在项目启动后，由产品经理用了大概一周时间设计了第一版的产品原型，召开两次需求评审会来确定最终的需求。

接下来设计组开始进行效果图设计，开发组进行技术研讨会确定技术选型，并确定接口文档，与前端人员确认。接口确认好，前端就按照效果图、接口文档进行前端代码的开发，而后端就按照产品原型、接口文档进行后端代码的开发。前后端开发完成后，前端和后端进行前后端联调。最后测试、上线部署。

### 问题三：你们项目组多少人?人员结构是什么？开发周期怎么定的？

....

### 问题四：Nacos

**为什么使用Nacos做注册中心和配置中心**

Nacos相比于其他产品，它一致性协议支持CP与AP，

除了服务的注册发现外，还支持动态的配置服务，消除了配置变更时重新部署应用和服务的需要，让配置管理变得高效敏捷，

国产物品上手容易，能通过简介的UI去进行服务与配置管理

同时还支持雪崩保护机制

### 问题五:RabbitMQ

**幂等性处理**

Mq的幂等可以通过在访问前设置全局id，存入redis的方式来处理，  每次消费前带着消费的全局id先在redis里查有没有这个id  有代表消费过了，返回重复消费信息给前台，在redis没有查到的话，表示是第一次消费，放行，让去消费，并保存这次的全局id

**谈一谈消息异步通信(谈谈你项目中MQ是怎么运用的)**

首先我们遇到的问题是,服务直接相互调用的时候之前一直采用的Fegin远程调用,也就是同步调用.但是这样紧耦合并且有很多业务之间并不需要消费者的反馈,可以使用异步调用,并且当时有延时取派件任务的需求.所以就去做方案设计,当时讨论解决方案之后,于是就提出了

解决异步调用可以使用SpringBoot集成的异步线程或者mq.延时取派件任务可以采用redis的zset数据类型的去重有序（分数排序）特点进行延迟和mq

但是既然消息中间件mq都可以做,就排除异步线程和redis,还可以确保消息的可靠性,剩下的就是在常用的几个消息中间件中做选择了:

**RabbitMQ优势**

几种常见MQ的对比：

|            | **RabbitMQ**            | **ActiveMQ**                   | **RocketMQ** | **Kafka**  |
| ---------- | ----------------------- | ------------------------------ | ------------ | ---------- |
| 公司/社区  | Rabbit                  | Apache                         | 阿里         | Apache     |
| 开发语言   | Erlang                  | Java                           | Java         | Scala&Java |
| 协议支持   | AMQP，XMPP，SMTP，STOMP | OpenWire,STOMP，REST,XMPP,AMQP | 自定义协议   | 自定义协议 |
| 可用性     | 高                      | 一般                           | 高           | 高         |
| 单机吞吐量 | 一般                    | 差                             | 高           | 非常高     |
| 消息延迟   | 微秒级                  | 毫秒级                         | 毫秒级       | 毫秒以内   |
| 消息可靠性 | 高                      | 一般                           | 高           | 一般       |

追求可用性：Kafka、 RocketMQ 、RabbitMQ

追求可靠性：RabbitMQ、RocketMQ

追求吞吐能力：RocketMQ、Kafka

追求消息低延迟：RabbitMQ、Kafka

**同步**

总结：

同步调用的优点：

- 时效性较强，可以立即得到结果

同步调用的问题：

- 耦合度高

- 性能和吞吐能力下降

- 有额外的资源消耗

- 有级联失败问题

  **异步**

好处：

- 吞吐量提升：无需等待订阅者处理完成，响应更快速
- 故障隔离：服务没有直接调用，不存在级联失败问题
- 调用间没有阻塞，不会造成无效的资源占用
- 耦合度极低，每个服务都可以灵活插拔，可替换
- 流量削峰：不管发布事件的流量波动多大，都由Broker接收，订阅者可以按照自己的速度去处理事件

缺点：

- 架构复杂了，业务没有明显的流程线，不好管理

- 需要依赖于Broker的可靠、安全、性能

  **项目中如何使用的mq**

我们把MQ进行了封装，设置成了一个微服务，因为在整个项目中每个需要使用MQ的微服务都要写很多配置与相同代码，为了让代码更简介其他小组也方便使用，所以进行了封装。

像调度中心与运单微服务中用MQ会用的比较多，调度中心对新增的运单进行监听，还有发送消息给到订单微服务去创建取派件任务，  还有运单微服务接收调度中心生成运输任务的消息等....



### 问题六:事物

**谈谈你对分布式事物的理解:**

事物的四大特性 原子性(事务同成功同失败) 一致性(数据一致) 隔离性(事务之间互不干扰互不可见) 持久性(持久化)

这是单体工程事物的四大特性, 但是如果使用到了微服务 分布式架构的情况下,  数据库都不是同一个了, 怎么保证数据的一致性 以及事物的原子性呢?

这个时候分布式事物的两大核心思想就提出来了,

```
CAP定理: c 数据一致性  a可用性  p分区容错性 在微服务分布式架构的情况下 cap是不可能同时满足的 ,要保证数据一致性,服务之间就需要相互等待数据的同步再进行展示把,这样可用性就降低了, 要保证可用性,数据的强一致就无法得到保证了

BASE理论: 讲究的则是 基本可用  软状态和最终一致.
Basically Available（基本可用）：分布式系统在出现故障时，允许损失部分可用性，即保证核心可用。
Soft State（软状态）：在一定时间内，允许出现中间状态，比如临时的不一致状态。
Eventually Consistent（最终一致性）：虽然无法保证强一致性，但是在软状态结束后，最终达到数据一致。
```

所以就引出了cp(强一致)和ap(高可用)两种开发模式.

建立在理论的基础上 Seata就诞生了.人类的智慧是无穷无尽的,

基于事物协调者 和 事务管理器(全局事物)以及资源管理器(分支事物)  开发了4种事物管理模式. 

- **XA模式**：强一致性分阶段事务模式，牺牲了一定的可用性，无业务侵入(事物协调者等待所有的分支事物提交成功之后再进行提交)CP

- **TCC模式**：最终一致的分阶段事务模式，有业务侵入(手动编写回滚逻辑以及提交逻辑比较麻烦啊,资源预留隔离,注意空回滚和业务悬挂/)

- **空回滚:**没有执行try的分支事物受其他分支事物影响进行了业务回滚cancel

- **业务悬挂:**对进行空回滚的分支事物进行try,导致事物永远不可能confirm或cancel ，事务一直处于中间状态

- **AT模式**：最终一致的分阶段事务模式，无业务侵入，也是Seata的默认模式(经典ap模式分支事物自己提交,如果出问题了再进行回滚,但是有可能出现脏读,全局锁隔离)

- **SAGA模式**：长事务模式，有业务侵入(分支事物自己提交,如果出问题了再根据手写的业务补偿进行回滚之类的操作,无隔离)

  **微服务如何根据这些配置寻找TC的地址呢？**

  我们知道注册到Nacos中的微服务，确定一个具体实例需要四个信息：

  - namespace：命名空间

  - group：分组

  - application：服务名

  - cluster：集群名

    **高可用**

    **集群:**Seata的TC服务作为分布式事务核心,搭建TC服务集群非常简单，启动多个TC服务，注册到nacos即可

    **异地机房容灾:**微服务基于事务组（tx-service-group)与TC集群的映射关系，来查找当前应该使用哪个TC集群。当SH集群故障时，只需要将vgroup-mapping中的映射关系改成HZ。则所有微服务就会切换到HZ的TC集群了。

    **基于MQ解决分布式事务原理：**

    采用最终一致性原理,确保生产者一定将增加积分的消息投递到MQ中， 采用：确认机制。
    确保消费者消费消息一定成功，如果没有异常情况下通知MQ删除该消息，否则情况下不断重试消费 。 采用：手动ack应答形式。
     注意：重试过程中，需要注意消息幂等性问题。
    如果MQ异步代码执行之后，代码出现异常的情况下，如何保证分布式事务问题。 
    采用：补偿队列

### 问题七:远程调用

**服务与服务之间怎么实现相互调用的?**

首先问题的产生,在单体架构的时候服务都是自己内部调用,Spring自动装备@Autowired依赖注入service就可以直接调用,但是进入分布式架构之后,运行的虚拟机不同,操作的数据库不同,tomcat不同,所以不能直接调用，我们项目上使用的Fegin技术，但远程调用都是建立在连接到注册中心的基础上的。

Feign是一个http请求调用的轻量级框架，可以以Java接口注解的方式调用Http请求。Spring Cloud引入 Feign并且集成了Ribbon实现客户端负载均衡调用.
原理是基于面向接口的动态代理方式生成实现类,

基于RequestBean,动态生成request,

使用Encoder将Bean转换成Http报文正文(消息解析和转码逻辑)

拦截器负责对请求和返回进行装饰处理,

最后发送http请求

Fegin优化:

GZIP压缩,

替换为HttpClient客户端(使用Http连接池提供性能)

### 问题八:网关

**项目中是否有用到网关?为什么?**

Gateway网关是所有微服务的统一入口, 它旨在为微服务架构提供一种简单有效的统一的 API 路由管理方式。

**权限控制**：网关作为微服务入口，需要校验用户是是否有请求资格，如果没有则进行拦截。

**路由和负载均衡**：一切请求都必须先经过gateway，但网关不处理业务，而是根据某种规则，把请求转发到某个微服务，这个过程叫做路由。当然路由的目标服务有多个时，还需要做负载均衡。

**限流**：当请求流量过高时，在网关中按照下流的微服务能够接受的速度来放行请求，避免服务压力过大。

**断言工厂(路由)**: 有很多种断言方式,比如最熟悉的就是**path路径断言**(请求路径必须符合指定规则),然后还有请求方式断言,请求头断言,cookie断言等等...

**过滤器工厂**:

① 对路由的请求或响应做加工处理，比如添加请求头

② 配置在路由下的过滤器只对当前路由的请求生效

defaultFilters的作用是什么？

① 对所有路由都生效的过滤器

**跨域问题**

跨域：域名不一致就是跨域，主要包括：

- 域名不同： www.taobao.com 和 www.taobao.org 和 www.jd.com 和 miaosha.jd.com
- 域名相同，端口不同：localhost:8080和localhost8081

**跨域问题：**浏览器禁止请求的发起者与服务端发生跨域ajax请求，请求被浏览器拦截的问题

**CORS**是一个W3C标准，全称是"跨域资源共享"（Cross-origin resource sharing）。它允许浏览器向跨源服务器，发出[`XMLHttpRequest`](https://www.ruanyifeng.com/blog/2012/09/xmlhttprequest_level_2.html)请求，从而克服了AJAX只能[同源](https://www.ruanyifeng.com/blog/2016/04/same-origin-policy.html)使用的限制.

**解决跨域问题:** 在网关配置中加全局配置

```
spring:
  cloud:
    gateway:
      # 。。。
      globalcors: # 全局的跨域处理
        add-to-simple-url-handler-mapping: true # 解决options请求被拦截问题
        corsConfigurations:
          '[/**]':
            allowedOrigins: # 允许哪些网站的跨域请求 
              - "http://localhost:8090"
            allowedMethods: # 允许的跨域ajax的请求方式
              - "GET"
              - "POST"
              - "DELETE"
              - "PUT"
              - "OPTIONS"
            allowedHeaders: "*" # 允许在请求中携带的头信息
            allowCredentials: true # 是否允许携带cookie
            maxAge: 360000 # 这次跨域检测的有效期
```

### 问题九:线程

**线程池7个参数**,核心线程数,最大线程数,存活时间,时间单位,阻塞队列,线程工厂,拒绝策略.

线程池执行流程,先查看核心线程是否满,没满创建线程执行,满了查看队列,队列满了,查看最大线程数.如果超过拒绝策略,没超过创建临时线程

**线程池复用原理**

线程池将线程和任务进行解耦，线程是线程，任务是任务，摆脱了之前通过 Thread 创建线程时的 一个线程必须对应一个任务的限制。 在线程池中，同一个线程可以从阻塞队列中不断获取新任务来执行，其核心原理在于线程池对 Thread 进行了封装，并不是每次执行任务都会调用 Thread.start() 来创建新线程，而是让每个线程去 执行一个“循环任务”，在这个“循环任务”中不停检查是否有任务需要被执行，如果有则直接执行，也就是调用任务中的 run 方法，将 run 方法当成一个普通的方法执行，通过这种方式只使用固定的线程就将所有任务的 run 方法串联起来。

**项目中是否用到多线程?**

....

### 问题十:mqsql

mysql数据库相关:

**mysql聚簇和非聚簇索引的区别:**聚簇索引(主键)按照顺序将索引和真实数据存储,非聚簇索引(非主键索引)存储的是主键索引指向的那一行数据的资源位置.

**mysql索引数据结构**:B+树

**mysql优化:**根据慢查询日志查看慢查询记录,找到运行较慢的sql,然后看是否需要优化,主要是 从几个方面,查询范围由小到大,尽量避免范围查询和分组查询,避免导致索引失效的查询语句,比如in notin,if null, not null,之类的. mybatis里使用where的时候带上标签,

**mybatis主键回显:**sql映射文件配置,useGeneratedKeys="true" keyProperty="id"

### 问题十一:Redis

**Redis和数据库的一致性**，这个问题可以通过延迟双删的方式去处理这个需要画个图理解一下比较好，但没办法保证强一致性，还有一种就是使用一些第三方组件  比如canel去解决

**5中数据类型以及对应的应用场景**

string 存储对象占用内存比hash小

list 队列 先进先出 lpush rpull

hash(map)存储对象, 购物车功能实现

set 无序去重,共同好友

zset  有序去重,  排行榜

**redis分布式锁:**

redision实现,利用zset的去重排序性.加上看门狗机制.

**redis集群方案:**

**主从复制----全量同步**

完整流程描述：

- slave节点请求增量同步
- master节点判断replid，发现不一致，拒绝增量同步
- master将完整内存数据生成RDB，发送RDB到slave
- slave清空本地数据，加载master的RDB
- master将RDB期间的命令记录在repl_baklog，并持续将log中的命令发送给slave
- slave执行接收到的命令，保持与master之间的同步

**主从复制----增量同步**

全量同步需要先做RDB，然后将RDB文件通过网络传输个slave，成本太高了。因此除了第一次做全量同步，其它大多数时候slave与master都是做**增量同步**。

什么是增量同步？就是只更新slave与master存在差异的部分数据。

**redis主从如何知道自己的数据有差异??** ---- 全量同步时的repl_baklog文件

**主从同步优化:**

可以从以下几个方面来优化Redis主从就集群：

- 在master中配置repl-diskless-sync yes启用无磁盘复制，避免全量同步时的磁盘IO。
- Redis单节点上的内存占用不要太大，减少RDB导致的过多磁盘IO
- 适当提高repl_baklog的大小，发现slave宕机时尽快实现故障恢复，尽可能避免全量同步
- 限制一个master上的slave节点数量，如果实在是太多slave，则可以采用主-从-从链式结构，减少master压力

**简述全量同步和增量同步区别？**

- 全量同步：master将完整内存数据生成RDB，发送RDB到slave。后续命令则记录在repl_baklog，逐个发送给slave。
- 增量同步：slave提交自己的offset到master，master获取repl_baklog中从offset之后的命令给slave

**什么时候执行全量同步？**

- slave节点第一次连接master节点时
- slave节点断开时间太久，repl_baklog中的offset已经被覆盖时

**什么时候执行增量同步？**

- slave节点断开又恢复，并且在repl_baklog中能找到offset时

**哨兵模式功能有:**

集群监控(每隔1秒发送一次ping命令，如果超过一定时间没有相向则认为是主观下线),消息通知,故障转移,配置中心

**分片集群:**散列插槽,集群伸缩,故障转移

主从和哨兵可以解决高可用、高并发读的问题。但是依然有两个问题没有解决：

- 海量数据存储问题
- 高并发写的问题

使用分片集群可以解决上述问题

**redis持久化机制:**

**RDB:**基于快照模式的持久化,redis默认的持久化方式,配置简单,性能较好

RDB方式bgsave的基本流程？

- fork主进程得到一个子进程，共享内存空间
- 子进程读取内存数据并写入新的RDB文件
- 用新RDB文件替换旧的RDB文件

RDB会在什么时候执行？save 60 1000代表什么含义？

- 默认是服务停止时
- 代表60秒内至少执行1000次修改则触发RDB

RDB的缺点？

- RDB执行间隔时间长，两次RDB之间写入数据有丢失的风险
- fork子进程、压缩、写出RDB文件都比较耗时

**AOF :**日志文本形式记录,AOF文件比RDB更新频率高，优先使用AOF还原数据。 AOF比RDB更安全也更大 ,RDB性能比AOF好 如果两个都配了优先加载AOF

AOF默认是关闭的，需要修改redis.conf配置文件来开启AOF：

```
# 是否开启AOF功能，默认是no
  appendonly yes
  # AOF文件的名称
  appendfilename "appendonly.aof"
```

AOF的命令记录的频率也可以通过redis.conf文件来配：

```
# 表示每执行一次写命令，立即记录到AOF文件
appendfsync always
# 写命令执行完先放入AOF缓冲区，然后表示每隔1秒将缓冲区数据写到AOF文件，是默认方案
appendfsync everysec
# 写命令执行完先放入AOF缓冲区，由操作系统决定何时将缓冲区内容写回磁盘
appendfsync no
```

Redis也会在触发阈值时自动去重写AOF文件。阈值也可以在redis.conf中配置：

```
# AOF文件比上次文件 增长超过多少百分比则触发重写
auto-aof-rewrite-percentage 100
# AOF文件体积最小多大以上才触发重写 
auto-aof-rewrite-min-size 64mb 
```

**多级缓存**

传统的缓存策略一般是请求到达Tomcat后，先查询Redis，如果未命中则查询数据库

多级缓存就是充分利用请求处理的每个环节，分别添加缓存，减轻Tomcat压力，提升服务性能：

- 浏览器访问静态资源时，优先读取浏览器本地缓存
- 访问非静态资源（ajax查询数据）时，访问服务端
- 请求到达Nginx后，优先读取Nginx本地缓存
- 如果Nginx本地缓存未命中，则去直接查询Redis（不经过Tomcat）
- 如果Redis查询未命中，则查询Tomcat
- 请求进入Tomcat后，优先查询JVM进程缓存
- 如果JVM进程缓存未命中，则查询数据库

**雪崩:**由于大量的key设置了相同的过期时间，一旦到达过期时间点，这些key集体失效，造成访问这些key的请求全部进入数据库

设置过期时间随机,热点数据持久化,缓存预热

**击穿:**某一热点数据存储到redis中，该数据处于高并发场景下，如果此时该key过期失效，这样就会有大量的并发请求进入数据库，对数据库产生大的压力，甚至宕机

热点数据持久化,漏桶算法

**穿透:**如果一个 key 在缓存和数据库都不存在，那么访问这个 key 每次都会进入数据库

布隆过滤器,或者设置一个null值在redis中

**预热**：
​		提前将相关数据加入到缓存系统

### 问题十二:Neo4j

....

### 问题十三:设计模式

**还了解其他设计模式吗**

.....

### 问题十四：动态代理原理

传统面向对象思想中，如果想要实现功能复用，要么继承、要么引用，无论哪种方式，对代码都有一定的侵入性，耦合无可避免, AOP正是为此而生，AOP旨在通过一种无耦合的方式来为程序带来增强。而动态代理就是AOP实现方式中的一种.

**动态代理:**动态创建,用到就创建,jdk动态代理(使用接口实现),cglib动态代理(基于重写实现)

**静态代理:**提前创建好代理对象

通过实现InvocationHandler 接⼝创建⾃⼰的调⽤处理器；

通过为Proxy 类指定 ClassLoader 对象和⼀组 interface 来创建动态代理类；

通过反射机制获得动态代理类的构造函数，其唯⼀参数类型是调⽤处理器接⼝类型；

通过构造函数创建动态代理类实例，构造时调⽤处理器对象作为参数被传⼊



### 

